{
 "cells": [
  {
   "attachments": {
    "195716de-c1d1-409d-ad86-df8e0668ad37.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "7e6c91d5",
   "metadata": {
    "papermill": {
     "duration": 0.005476,
     "end_time": "2023-03-02T20:54:46.588627",
     "exception": false,
     "start_time": "2023-03-02T20:54:46.583151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"border-radius: 20px; background-color: #86c7ff; font-family: Roboto Mono;\"><h1 style=\"padding-left: 22px; padding-top: 10px; padding-bottom: 10px; color: black;\">Understanding CNN part#2</h1></div>\n",
    "This notebook is the natural sequel of my previous notebook:\n",
    "\n",
    "[Understanding CNN](https://www.kaggle.com/code/fid0did0/understandig-cnn-layer-by-layer-on-digit-reco)\n",
    "\n",
    "On That notebook the \"features map\" was generated when the CNN input was feed with one samples from calss \"3\", one samples from calss \"5\" and one samples from calss \"1\".\n",
    "The \"features map\" means the intermediate product generated by the CNN after the \"max_pooling2d_2\" layer and jut before the last two dense layers.\n",
    "\n",
    "The final picture generated was this one:\n",
    "\n",
    "![prev_result.png](attachment:195716de-c1d1-409d-ad86-df8e0668ad37.png)\n",
    "\n",
    "where each one of the 128 pixel shows the output generated at the layer \"max_pooling2d_2\" output (shape 1,1,1,128). Because I was using three different samples I used the color to differentiate the three results. The red color is used to show the results when the sample of class \"3\" was feed, the green when feeding with sample of class \"5\" and blue when feeding with sample of class \"1\". Yellow, cyan and magenta means that the \"feature\" was activated by two classes.\n",
    "\n",
    "In this notebook I'm going to syntesize the \"features map\" at the same layer (\"max_pooling2d_2\") required to generate the \"pure\" output for the class used, to see if the map match the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb2aed5d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-02T20:54:46.600345Z",
     "iopub.status.busy": "2023-03-02T20:54:46.599814Z",
     "iopub.status.idle": "2023-03-02T20:54:56.959971Z",
     "shell.execute_reply": "2023-03-02T20:54:56.958612Z"
    },
    "papermill": {
     "duration": 10.370246,
     "end_time": "2023-03-02T20:54:56.963654",
     "exception": false,
     "start_time": "2023-03-02T20:54:46.593408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/refmodel/understand_cnn/saved_model.pb\n",
      "/kaggle/input/refmodel/understand_cnn/keras_metadata.pb\n",
      "/kaggle/input/refmodel/understand_cnn/variables/variables.index\n",
      "/kaggle/input/refmodel/understand_cnn/variables/variables.data-00000-of-00001\n",
      "/kaggle/input/digit-recognizer/sample_submission.csv\n",
      "/kaggle/input/digit-recognizer/train.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as krs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc37dfbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T20:54:56.976283Z",
     "iopub.status.busy": "2023-03-02T20:54:56.975206Z",
     "iopub.status.idle": "2023-03-02T20:54:58.691902Z",
     "shell.execute_reply": "2023-03-02T20:54:58.690312Z"
    },
    "papermill": {
     "duration": 1.730142,
     "end_time": "2023-03-02T20:54:58.698700",
     "exception": false,
     "start_time": "2023-03-02T20:54:56.968558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_model=krs.models.load_model('/kaggle/input/refmodel/understand_cnn')\n",
    "#ref_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5136d6b1",
   "metadata": {
    "papermill": {
     "duration": 0.004026,
     "end_time": "2023-03-02T20:54:58.707282",
     "exception": false,
     "start_time": "2023-03-02T20:54:58.703256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This time I'm intrested on the last two \"dense\" layers, the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a458e9cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T20:54:58.718841Z",
     "iopub.status.busy": "2023-03-02T20:54:58.718262Z",
     "iopub.status.idle": "2023-03-02T20:54:58.770648Z",
     "shell.execute_reply": "2023-03-02T20:54:58.769306Z"
    },
    "papermill": {
     "duration": 0.061677,
     "end_time": "2023-03-02T20:54:58.773400",
     "exception": false,
     "start_time": "2023-03-02T20:54:58.711723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1, 1, 128)]       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 1, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,594\n",
      "Trainable params: 35,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = krs.models.Model(inputs=ref_model.get_layer('dropout_2').input, outputs=ref_model.output)\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594831b",
   "metadata": {
    "papermill": {
     "duration": 0.005463,
     "end_time": "2023-03-02T20:54:58.785027",
     "exception": false,
     "start_time": "2023-03-02T20:54:58.779564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The strategy used here is to synthesize the \"feature map\" that maximize the activation of one specific class, or minimize the loss vs the expected target class. This sentence sound like an optimization process, so the gradient descend algorithm wil be perfect to achieve the result. The process will be similar to the process used by the neural network to learn its weights, but now the \"trainable parameters\" will be the value of the input \"feature map\" having the layer weight frozen.\n",
    "To execute this process I'm starting defining a loss function between the \"label\" generated by the \"feature map\" feed to the function and the expected ideal target (a vector where all the index are zero but the target class index is one).\n",
    "\n",
    "At this point I initialize the \"feature map\" zeroing all the elements.\n",
    "I'm then evaluating the gradients of the activation loss function versus the activation map elements and finally I'm invoking the optimizer in order to modify the \"feature map\" in the direction that minimize the loss.\n",
    "I'm iterating the process for 100 time and repeat the process for the three class used: \"3\", \"5\" and \"1\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ffeeb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T20:54:58.799756Z",
     "iopub.status.busy": "2023-03-02T20:54:58.798625Z",
     "iopub.status.idle": "2023-03-02T20:55:02.488431Z",
     "shell.execute_reply": "2023-03-02T20:55:02.486829Z"
    },
    "papermill": {
     "duration": 3.701027,
     "end_time": "2023-03-02T20:55:02.491896",
     "exception": false,
     "start_time": "2023-03-02T20:54:58.790869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def activation_loss(input_tensor, max_idx):\n",
    "    target = tf.Variable(tf.zeros(10))\n",
    "    target=target[max_idx].assign(1)\n",
    "    label = classifier(input_tensor)\n",
    "    loss = loss = tf.keras.losses.mean_squared_error(target, label)\n",
    "    return loss\n",
    "\n",
    "activation_r = tf.Variable(tf.zeros((1, 1, 1, 128)))\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.1)\n",
    "for i in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        act_loss = activation_loss(activation_r, 3)\n",
    "    gradients = tape.gradient(act_loss, activation_r)\n",
    "    optimizer.apply_gradients([(gradients, activation_r)])\n",
    "\n",
    "activation_g = tf.Variable(tf.zeros((1, 1, 1, 128)))\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.1)\n",
    "for i in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        act_loss = activation_loss(activation_g, 5)\n",
    "    gradients = tape.gradient(act_loss, activation_g)\n",
    "    optimizer.apply_gradients([(gradients, activation_g)])\n",
    "\n",
    "activation_b = tf.Variable(tf.zeros((1, 1, 1, 128)))\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.1)\n",
    "for i in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        act_loss = activation_loss(activation_b, 1)\n",
    "    gradients = tape.gradient(act_loss, activation_b)\n",
    "    optimizer.apply_gradients([(gradients, activation_b)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a124744e",
   "metadata": {
    "papermill": {
     "duration": 0.005404,
     "end_time": "2023-03-02T20:55:02.503624",
     "exception": false,
     "start_time": "2023-03-02T20:55:02.498220",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "At this point I can combine the resulted vector in an RGB vector read to be shown as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "549f84ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T20:55:02.517757Z",
     "iopub.status.busy": "2023-03-02T20:55:02.517165Z",
     "iopub.status.idle": "2023-03-02T20:55:02.812110Z",
     "shell.execute_reply": "2023-03-02T20:55:02.809949Z"
    },
    "papermill": {
     "duration": 0.307291,
     "end_time": "2023-03-02T20:55:02.816593",
     "exception": false,
     "start_time": "2023-03-02T20:55:02.509302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 3.5, -0.5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABiIAAADVCAYAAADaZeggAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAJVElEQVR4nO3bsaolVQKG0V0q4zgmzYCRD9DMIwhmjUFHomDsAxiLIBoNMzAY+wCmJmJkMBqKjzDQuZmoiYoo7AnE/EDdj3139VrxCf6iate53R/nmHPOAQAAAAAAEHhm9QAAAAAAAOC6hAgAAAAAACAjRAAAAAAAABkhAgAAAAAAyAgRAAAAAABARogAAAAAAAAyQgQAAAAAAJARIgAAAAAAgMxzt37wOI5yB0+Bj1cPuAPv/PLz6gmnzL/+bfWE03Z/Fc25esE5x/H76gl34NnVA07a/BCMMca/Vw846f3VA+7At5u/jF6+wDnY3v9WDzjpH6sHPPXmeLR6wmnH/Gr1hFM+Wj3gDrx7/LR6wkkvrh5w0hurB9yBz1YPeOpt/lfpFf51Nv47Plk94ZTXxturJ5yy+xkYY9z8n11+EQEAAAAAAGSECAAAAAAAICNEAAAAAAAAGSECAAAAAADICBEAAAAAAEBGiAAAAAAAADJCBAAAAAAAkBEiAAAAAACAjBABAAAAAABkhAgAAAAAACAjRAAAAAAAABkhAgAAAAAAyAgRAAAAAABARogAAAAAAAAyQgQAAAAAAJARIgAAAAAAgIwQAQAAAAAAZIQIAAAAAAAgI0QAAAAAAAAZIQIAAAAAAMgIEQAAAAAAQEaIAAAAAAAAMkIEAAAAAACQESIAAAAAAICMEAEAAAAAAGSECAAAAAAAICNEAAAAAAAAGSECAAAAAADICBEAAAAAAEBGiAAAAAAAADJCBAAAAAAAkBEiAAAAAACAjBABAAAAAABkhAgAAAAAACAjRAAAAAAAABkhAgAAAAAAyAgRAAAAAABARogAAAAAAAAyQgQAAAAAAJARIgAAAAAAgIwQAQAAAAAAZIQIAAAAAAAgI0QAAAAAAAAZIQIAAAAAAMgIEQAAAAAAQEaIAAAAAAAAMkIEAAAAAACQOeac86YP/uWot7R+Wz2A2560++3Y/Bj8c/WAO/Dh6gEnfbp6wElvrR5wBzY/xmNc4F3qJtwHn60ecNKbqwecc4VHaHfHFW7C3i/TK9yB3e39BP1p9yfpX6sHnPTB6gF3YPdnaP+TvPsd2P8C9vdk82Pw8ALP0LzxIPhFBAAAAAAAkBEiAAAAAACAjBABAAAAAABkhAgAAAAAACAjRAAAAAAAABkhAgAAAAAAyAgRAAAAAABARogAAAAAAAAyQgQAAAAAAJARIgAAAAAAgIwQAQAAAAAAZIQIAAAAAAAgI0QAAAAAAAAZIQIAAAAAAMgIEQAAAAAAQEaIAAAAAAAAMkIEAAAAAACQESIAAAAAAICMEAEAAAAAAGSECAAAAAAAICNEAAAAAAAAGSECAAAAAADICBEAAAAAAEBGiAAAAAAAADJCBAAAAAAAkBEiAAAAAACAjBABAAAAAABkhAgAAAAAACAjRAAAAAAAABkhAgAAAAAAyAgRAAAAAABARogAAAAAAAAyQgQAAAAAAJARIgAAAAAAgIwQAQAAAAAAZIQIAAAAAAAgI0QAAAAAAAAZIQIAAAAAAMgIEQAAAAAAQEaIAAAAAAAAMkIEAAAAAACQESIAAAAAAICMEAEAAAAAAGSECAAAAAAAICNEAAAAAAAAGSECAAAAAADICBEAAAAAAEBGiAAAAAAAADLHnHPe9MHjqLekbrrI+273i9j7ERpjjHHML1ZPOOnx6gGn7X4MxvH96gWnHOPvqyecNsd7qyecM/+zesFpx7H7Sb7AF9r2Pl894Jz5+uoFp/2wesBJDy5wjLe/hN2/Csa4wE3Y3y+bP0cvbP430fz1Aofg+b3vwQXuwBhz86vYfP4YY//v5OPL1QtOerR6wGm31QW/iAAAAAAAAEJCBAAAAAAAkBEiAAAAAACAjBABAAAAAABkhAgAAAAAACAjRAAAAAAAABkhAgAAAAAAyAgRAAAAAABARogAAAAAAAAyQgQAAAAAAJARIgAAAAAAgIwQAQAAAAAAZIQIAAAAAAAgI0QAAAAAAAAZIQIAAAAAAMgIEQAAAAAAQEaIAAAAAAAAMkIEAAAAAACQESIAAAAAAICMEAEAAAAAAGSECAAAAAAAICNEAAAAAAAAGSECAAAAAADICBEAAAAAAEBGiAAAAAAAADJCBAAAAAAAkBEiAAAAAACAjBABAAAAAABkhAgAAAAAACAjRAAAAAAAABkhAgAAAAAAyAgRAAAAAABARogAAAAAAAAyQgQAAAAAAJARIgAAAAAAgIwQAQAAAAAAZIQIAAAAAAAgI0QAAAAAAAAZIQIAAAAAAMgIEQAAAAAAQEaIAAAAAAAAMkIEAAAAAACQESIAAAAAAICMEAEAAAAAAGSECAAAAAAAICNEAAAAAAAAGSECAAAAAADIHHPOedMHj6Pe0rrpKu+5zW/BFez+GF3iEbrtlXV/Pdz8LjxZPYDNT8AYY4xj86uY13ibbm3/O7D3GfjD16sHnPTq6gGw3BxfrJ5w2jEer55w0hW+D/b24+a34MH+fxSNMb5bPeCkl1YPeOrNzd+lr8z9D/I3N94Dv4gAAAAAAAAyQgQAAAAAAJARIgAAAAAAgIwQAQAAAAAAZIQIAAAAAAAgI0QAAAAAAAAZIQIAAAAAAMgIEQAAAAAAQEaIAAAAAAAAMkIEAAAAAACQESIAAAAAAICMEAEAAAAAAGSECAAAAAAAICNEAAAAAAAAGSECAAAAAADICBEAAAAAAEBGiAAAAAAAADJCBAAAAAAAkBEiAAAAAACAjBABAAAAAABkhAgAAAAAACAjRAAAAAAAABkhAgAAAAAAyAgRAAAAAABARogAAAAAAAAyQgQAAAAAAJARIgAAAAAAgIwQAQAAAAAAZIQIAAAAAAAgI0QAAAAAAAAZIQIAAAAAAMgIEQAAAAAAQEaIAAAAAAAAMkIEAAAAAACQESIAAAAAAICMEAEAAAAAAGSECAAAAAAAICNEAAAAAAAAGSECAAAAAADICBEAAAAAAEBGiAAAAAAAADJCBAAAAAAAkBEiAAAAAACAjBABAAAAAABkhAgAAAAAACAjRAAAAAAAABkhAgAAAAAAyAgRAAAAAABA5phzztUjAAAAAACAa/KLCAAAAAAAICNEAAAAAAAAGSECAAAAAADICBEAAAAAAEBGiAAAAAAAADJCBAAAAAAAkBEiAAAAAACAjBABAAAAAABkhAgAAAAAACDzfw5MbpRNSlDQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2000x6000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=np.stack([activation_r.numpy()[0,0,0,:].reshape(4, 32),\n",
    "              activation_g.numpy()[0,0,0,:].reshape(4, 32),\n",
    "              activation_b.numpy()[0,0,0,:].reshape(4, 32)], axis=2)\n",
    "img_min=np.amin(img)\n",
    "img_max=np.amax(img)\n",
    "#print(img_min)\n",
    "#print(img_max)\n",
    "\n",
    "plt.figure(figsize=(20, 60))\n",
    "plt.imshow(img, vmin=img_min, vmax=img_max)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8520b6a8",
   "metadata": {
    "papermill": {
     "duration": 0.005646,
     "end_time": "2023-03-02T20:55:02.828482",
     "exception": false,
     "start_time": "2023-03-02T20:55:02.822836",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Definitively the picture is not equal to the one generated by the three samples at the CNN input, but for sure there are several similar pattern. Furthermore is possible to recognize that in the latter picture more \"features\" are activated compared with the picture from the samples.\n",
    "\n",
    "In my opinion this behaviour is obtained because one sample activate only some features, while the synthesized picture highlights all the features where one class shall be sensitive, in order to recognize the same digit class written with different \"style\".\n",
    "\n",
    "Clearly this is just my personal interpretation, if you have differet or alternative opinion, please write down in the discussion area, I'm looking forward to exchange opinion.\n",
    "The same if you have remarks or advice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4632071c",
   "metadata": {
    "papermill": {
     "duration": 0.005736,
     "end_time": "2023-03-02T20:55:02.840214",
     "exception": false,
     "start_time": "2023-03-02T20:55:02.834478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Just before to close I want to verify that using the activation map syntesized for a class \"3\", the CNN really predict a \"3\". Just to be sure that I didn't make big mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63fb54cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T20:55:02.854346Z",
     "iopub.status.busy": "2023-03-02T20:55:02.853793Z",
     "iopub.status.idle": "2023-03-02T20:55:03.192839Z",
     "shell.execute_reply": "2023-03-02T20:55:03.191225Z"
    },
    "papermill": {
     "duration": 0.349697,
     "end_time": "2023-03-02T20:55:03.195788",
     "exception": false,
     "start_time": "2023-03-02T20:55:02.846091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 240ms/step\n",
      "[[4.2387205e-06 2.9287571e-06 2.6298856e-05 9.9937940e-01 1.0079852e-06\n",
      "  3.2113295e-04 1.4320403e-06 8.2764782e-06 2.1807227e-04 3.7183872e-05]]\n"
     ]
    }
   ],
   "source": [
    "x_ver=activation_r.numpy()\n",
    "x_ver=x_ver.reshape(1,1,1,128)\n",
    "y_ver = classifier.predict(x_ver)\n",
    "print(y_ver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a2802",
   "metadata": {
    "papermill": {
     "duration": 0.005997,
     "end_time": "2023-03-02T20:55:03.208024",
     "exception": false,
     "start_time": "2023-03-02T20:55:03.202027",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Luckly It seems I didn't make big mistake!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492da51b",
   "metadata": {
    "papermill": {
     "duration": 0.005746,
     "end_time": "2023-03-02T20:55:03.219919",
     "exception": false,
     "start_time": "2023-03-02T20:55:03.214173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Further Investigation\n",
    "\n",
    "To extend the CNN analysis I would like to use a technique called \"class activation map visualization\" to identify the area of a picture feed at CNN input where the CNN is highly sensitive. So stay tuned if you like these kind of analysis.\n",
    "\n",
    "Enjoy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31.948882,
   "end_time": "2023-03-02T20:55:06.607533",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-02T20:54:34.658651",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
